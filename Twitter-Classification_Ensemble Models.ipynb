{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Project 3 : Buzz Prediction on Twitter\n",
    "\n",
    "Project Description:\n",
    "- Use same datasets as Project 2.\n",
    "- Run all the models only on 10% data. Use code given in Project 2 for sampling.\n",
    "- Preprocess data: Explore data and apply data scaling.\n",
    "\n",
    "Regression Task:\n",
    "- Apply any two models with bagging and any two models with pasting.\n",
    "- Apply any two models with adaboost boosting\n",
    "- Apply one model with gradient boosting\n",
    "- Apply PCA on data and then apply all the models in project 2 again on data you get from PCA. Compare your results with results in project 2. You don't need to apply all the models twice. Just copy the result table from project 2, prepare similar table for all the models after PCA and compare both tables. Does PCA help in getting better results?\n",
    "- Apply deep learning models covered in class\n",
    "\n",
    "Classification Task:\n",
    "- Apply four voting classifiers - two with hard voting and two with soft voting\n",
    "- Apply any two models with bagging and any two models with pasting.\n",
    "- Apply any two models with adaboost boosting\n",
    "- Apply one model with gradient boosting\n",
    "- Apply PCA on data and then apply all the models in project 2 again on data you get from PCA. Compare your results with results in project 2. You don't need to apply all the models twice. Just copy the result table from project 2, prepare similar table for all the models after PCA and compare both tables. Does PCA help in getting better results?\n",
    "- Apply deep learning models covered in class\n",
    "\n",
    "Deliverables:\n",
    "- Use markdown to provide inline comments for this project.\n",
    "- Your outputs should be clearly executed in the notebook i.e. we should not need to rerun the code to obtain the outputs.\n",
    "- Visualization encouraged.\n",
    "- If you are submitting two different files, then please only one group member submit both the files. If you submit two files separately from different accounts, it will be submitted as two different attempts.\n",
    "- If you are submitting two different files, then please follow below naming convetion:\n",
    "    Project3_Regression_GroupXX_Firstname1_Firstname2.ipynb\n",
    "    Project3_Classification_GroupXX_Firstname1_Firstname2.ipynb\n",
    "- If you are submitting single file, then please follow below naming convetion:\n",
    "    Project3_Both_GroupXX_Firstname1_Firstname2.ipynb\n",
    "\n",
    "Questions regarding the project:\n",
    "- We have created a discussion board under Projects folder on e-learning. Create threads over there and post your queries related to project there.\n",
    "- We will also answer queries there. We will not be answering any project related queries through the mail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliri\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\aliri\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\aliri\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"C:\\Users\\aliri\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"C:\\Users\\aliri\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"C:\\Users\\aliri\\Anaconda3\\lib\\imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"C:\\Users\\aliri\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: DLL load failed: The specified module could not be found.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0m_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\imp.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(name, file, filename, details)\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[1;34m(name, path, file)\u001b[0m\n\u001b[0;32m    342\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[1;32m--> 343\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified module could not be found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-54ac00f69fe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscikit_learn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Globally-importable utils.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcomponent_api_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[1;32m---> 74\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\aliri\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"C:\\Users\\aliri\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"C:\\Users\\aliri\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"C:\\Users\\aliri\\Anaconda3\\lib\\imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"C:\\Users\\aliri\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: DLL load failed: The specified module could not be found.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "import numpy.random as nr\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as sklm\n",
    "import scipy.stats as ss\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import cross_validation\n",
    "from sklearn import svm, preprocessing\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from  sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Twitter-Absolute-Sigma-500.data', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['Number of Created Discussions 0'\n",
    ",'Number of Created Discussions 1',\n",
    "'Number of Created Discussions 2',\n",
    "'Number of Created Discussions 3',\n",
    "'Number of Created Discussions 4',\n",
    "'Number of Created Discussions 5',\n",
    "'Number of Created Discussions 6',\n",
    "'Author Increase 0',\n",
    "'Author Increase 1',\n",
    "'Author Increase 2',\n",
    "'Author Increase 3',\n",
    "'Author Increase 4',\n",
    "'Author Increase 5',\n",
    "'Author Increase 6',\n",
    "'Attention Level 0',\n",
    "'Attention Level 1',\n",
    "'Attention Level 2',\n",
    "'Attention Level 3',\n",
    "'Attention Level 4',\n",
    "'Attention Level 5',\n",
    "'Attention Level 6',\n",
    "'Burstiness Level 0',\n",
    "'Burstiness Level 1',\n",
    "'Burstiness Level 2',\n",
    "'Burstiness Level 3',\n",
    "'Burstiness Level 4',\n",
    "'Burstiness Level 5',\n",
    "'Burstiness Level 6',\n",
    "'Number of Atomic Containers 0',\n",
    "'Number of Atomic Containers 1',\n",
    "'Number of Atomic Containers 2',\n",
    "'Number of Atomic Containers 3',\n",
    "'Number of Atomic Containers 4',\n",
    "'Number of Atomic Containers 5',\n",
    "'Number of Atomic Containers 6',\n",
    "'Number of Contributions 0',\n",
    "'Number of Contributions 1',\n",
    "'Number of Contributions 2',\n",
    "'Number of Contributions 3',\n",
    "'Number of Contributions 4',\n",
    "'Number of Contributions 5',\n",
    "'Number of Contributions 6',\n",
    "'Contribution Sparseness 0',\n",
    "'Contribution Sparseness 1',\n",
    "'Contribution Sparseness 2',\n",
    "'Contribution Sparseness 3',\n",
    "'Contribution Sparseness 4',\n",
    "'Contribution Sparseness 5',\n",
    "'Contribution Sparseness 6',\n",
    "'Author Interaction 0',\n",
    "'Author Interaction 1',\n",
    "'Author Interaction 2',\n",
    "'Author Interaction 3',\n",
    "'Author Interaction 4',\n",
    "'Author Interaction 5',\n",
    "'Author Interaction 6',\n",
    "'Number of Authors 0',\n",
    "'Number of Authors 1',\n",
    "'Number of Authors 2',\n",
    "'Number of Authors 3',\n",
    "'Number of Authors 4',\n",
    "'Number of Authors 5',\n",
    "'Number of Authors 6',\n",
    "'Average Discussions Length 0',\n",
    "'Average Discussions Length 1',\n",
    "'Average Discussions Length 2',\n",
    "'Average Discussions Length 3',\n",
    "'Average Discussions Length 4',\n",
    "'Average Discussions Length 5',\n",
    "'Average Discussions Length 6',\n",
    "'Number of Discussions 0',\n",
    "'Number of Discussions 1',\n",
    "'Number of Discussions 2',\n",
    "'Number of Discussions 3',\n",
    "'Number of Discussions 4',\n",
    "'Number of Discussions 5',\n",
    "'Number of Discussions 6','Annotation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=df[['Number of Created Discussions 0'\n",
    ",'Number of Created Discussions 1',\n",
    "'Number of Created Discussions 2',\n",
    "'Number of Created Discussions 3',\n",
    "'Number of Created Discussions 4',\n",
    "'Number of Created Discussions 5',\n",
    "'Number of Created Discussions 6',\n",
    "'Author Increase 0',\n",
    "'Author Increase 1',\n",
    "'Author Increase 2',\n",
    "'Author Increase 3',\n",
    "'Author Increase 4',\n",
    "'Author Increase 5',\n",
    "'Author Increase 6',\n",
    "'Attention Level 0',\n",
    "'Attention Level 1',\n",
    "'Attention Level 2',\n",
    "'Attention Level 3',\n",
    "'Attention Level 4',\n",
    "'Attention Level 5',\n",
    "'Attention Level 6',\n",
    "'Burstiness Level 0',\n",
    "'Burstiness Level 1',\n",
    "'Burstiness Level 2',\n",
    "'Burstiness Level 3',\n",
    "'Burstiness Level 4',\n",
    "'Burstiness Level 5',\n",
    "'Burstiness Level 6',\n",
    "'Number of Atomic Containers 0',\n",
    "'Number of Atomic Containers 1',\n",
    "'Number of Atomic Containers 2',\n",
    "'Number of Atomic Containers 3',\n",
    "'Number of Atomic Containers 4',\n",
    "'Number of Atomic Containers 5',\n",
    "'Number of Atomic Containers 6',\n",
    "'Number of Contributions 0',\n",
    "'Number of Contributions 1',\n",
    "'Number of Contributions 2',\n",
    "'Number of Contributions 3',\n",
    "'Number of Contributions 4',\n",
    "'Number of Contributions 5',\n",
    "'Number of Contributions 6',\n",
    "'Contribution Sparseness 0',\n",
    "'Contribution Sparseness 1',\n",
    "'Contribution Sparseness 2',\n",
    "'Contribution Sparseness 3',\n",
    "'Contribution Sparseness 4',\n",
    "'Contribution Sparseness 5',\n",
    "'Contribution Sparseness 6',\n",
    "'Author Interaction 0',\n",
    "'Author Interaction 1',\n",
    "'Author Interaction 2',\n",
    "'Author Interaction 3',\n",
    "'Author Interaction 4',\n",
    "'Author Interaction 5',\n",
    "'Author Interaction 6',\n",
    "'Number of Authors 0',\n",
    "'Number of Authors 1',\n",
    "'Number of Authors 2',\n",
    "'Number of Authors 3',\n",
    "'Number of Authors 4',\n",
    "'Number of Authors 5',\n",
    "'Number of Authors 6',\n",
    "'Average Discussions Length 0',\n",
    "'Average Discussions Length 1',\n",
    "'Average Discussions Length 2',\n",
    "'Average Discussions Length 3',\n",
    "'Average Discussions Length 4',\n",
    "'Average Discussions Length 5',\n",
    "'Average Discussions Length 6',\n",
    "'Number of Discussions 0',\n",
    "'Number of Discussions 1',\n",
    "'Number of Discussions 2',\n",
    "'Number of Discussions 3',\n",
    "'Number of Discussions 4',\n",
    "'Number of Discussions 5',\n",
    "'Number of Discussions 6']]\n",
    "y1=df['Annotation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "_, sample_data, _, sample_target = train_test_split(X1, y1, shuffle = True, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=sample_data\n",
    "y=sample_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14071, 77)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_org,X_test_org,y_train,y_test=train_test_split(X,y,random_state=18)\n",
    "X_train=scaler.fit_transform(X_train_org)\n",
    "X_test=scaler.transform(X_test_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hard voting classifiers on Logistic Regression and K Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9670267197271177\n",
      "KNeighborsClassifier 0.9644684479818079\n",
      "VotingClassifier 0.9673109721432632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliri\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression(C = 100)\n",
    "log_clf.fit(X_train, y_train)\n",
    "knn_clf = KNeighborsClassifier(20)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('knn', knn_clf)], voting='hard')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, knn_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soft voting classifiers on SVC and Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC 0.9656054576463899\n",
      "DecisionTreeClassifier 0.957646389994315\n",
      "VotingClassifier 0.9644684479818079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliri\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC(C = 1000,gamma = 0.01, probability = True)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "voting_clf2 = VotingClassifier(estimators=[('svc', svm_clf), ('dt',tree_clf )], voting='soft')\n",
    "voting_clf2.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (svm_clf,tree_clf, voting_clf2):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging and Pasting Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging classifier on Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966173962478681\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(max_depth=2)\n",
    "bag1_clf = BaggingClassifier(dt_clf, n_estimators=500, max_samples=100, bootstrap=True, n_jobs=-1, random_state=0)\n",
    "\n",
    "bag1_clf.fit(X_train, y_train)\n",
    "y_pred = bag1_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.96\n",
      "Test score: 0.97\n"
     ]
    }
   ],
   "source": [
    "print('Train score: {:.2f}'.format(bag1_clf.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(bag1_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive      2748                58\n",
      "Actual negative        61               651\n",
      "\n",
      "Accuracy        0.97\n",
      "AUC             0.99\n",
      "Macro precision 0.95\n",
      "Macro recall    0.95\n",
      " \n",
      "           Positive      Negative\n",
      "Num case     2806           712\n",
      "Precision    0.98          0.92\n",
      "Recall       0.98          0.91\n",
      "F1           0.98          0.92\n"
     ]
    }
   ],
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "\n",
    "probabilities = bag1_clf.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging classifier on K Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9297896532120523\n"
     ]
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(20)\n",
    "bag2_clf = BaggingClassifier(knn_clf, n_estimators=500, max_samples=100, bootstrap=True, n_jobs=-1, random_state=0)\n",
    "\n",
    "bag2_clf.fit(X_train, y_train)\n",
    "y_pred = bag2_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.92\n",
      "Test score: 0.93\n"
     ]
    }
   ],
   "source": [
    "print('Train score: {:.2f}'.format(bag2_clf.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(bag2_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive      2798                 8\n",
      "Actual negative       239               473\n",
      "\n",
      "Accuracy        0.93\n",
      "AUC             0.99\n",
      "Macro precision 0.95\n",
      "Macro recall    0.83\n",
      " \n",
      "           Positive      Negative\n",
      "Num case     2806           712\n",
      "Precision    0.92          0.98\n",
      "Recall       1.00          0.66\n",
      "F1           0.96          0.79\n"
     ]
    }
   ],
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = bag2_clf.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pasting classifier on SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9565093803297328\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC(C = 1000,gamma = 0.01, probability = True)\n",
    "bag3_clf = BaggingClassifier(svm_clf, n_estimators=500, max_samples=100, bootstrap=False, n_jobs=-1, random_state=0)\n",
    "\n",
    "bag3_clf.fit(X_train, y_train)\n",
    "y_pred = bag3_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.95\n",
      "Test score: 0.96\n"
     ]
    }
   ],
   "source": [
    "print('Train score: {:.2f}'.format(bag3_clf.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(bag3_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive      2784                22\n",
      "Actual negative       131               581\n",
      "\n",
      "Accuracy        0.96\n",
      "AUC             0.99\n",
      "Macro precision 0.96\n",
      "Macro recall    0.90\n",
      " \n",
      "           Positive      Negative\n",
      "Num case     2806           712\n",
      "Precision    0.96          0.96\n",
      "Recall       0.99          0.82\n",
      "F1           0.97          0.88\n"
     ]
    }
   ],
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = bag3_clf.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pasting classifier on Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9567936327458784\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression(C = 100)\n",
    "bag4_clf = BaggingClassifier(log_clf, n_estimators=500, max_samples=100, bootstrap=False, n_jobs=-1, random_state=0)\n",
    "\n",
    "bag4_clf.fit(X_train, y_train)\n",
    "y_pred = bag4_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.95\n",
      "Test score: 0.96\n"
     ]
    }
   ],
   "source": [
    "print('Train score: {:.2f}'.format(bag4_clf.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(bag4_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive      2775                31\n",
      "Actual negative       121               591\n",
      "\n",
      "Accuracy        0.96\n",
      "AUC             0.99\n",
      "Macro precision 0.95\n",
      "Macro recall    0.91\n",
      " \n",
      "           Positive      Negative\n",
      "Num case     2806           712\n",
      "Precision    0.96          0.95\n",
      "Recall       0.99          0.83\n",
      "F1           0.97          0.89\n"
     ]
    }
   ],
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = bag4_clf.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost Boosting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaboost on Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best parameter for learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"learning_rate\": [0.1, 1, 10]}\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2), n_estimators=200, random_state=0)\n",
    "ada_clf_grid = ms.GridSearchCV(estimator = ada_clf, param_grid = param_grid, \n",
    "                      cv = 5,\n",
    "                      return_train_score = True)\n",
    "ada_clf_grid.fit(X_train, y_train)\n",
    "print(ada_clf_grid.best_estimator_.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9602046617396248\n"
     ]
    }
   ],
   "source": [
    "ada_clf_dt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2), n_estimators=200, learning_rate=1,random_state=0)\n",
    "ada_clf_dt.fit(X_train, y_train)\n",
    "y_pred = ada_clf_dt.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 0.96\n"
     ]
    }
   ],
   "source": [
    "print('Train score: {:.2f}'.format(ada_clf_dt.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(ada_clf_dt.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive      2739                67\n",
      "Actual negative        73               639\n",
      "\n",
      "Accuracy        0.96\n",
      "AUC             0.99\n",
      "Macro precision 0.94\n",
      "Macro recall    0.94\n",
      " \n",
      "           Positive      Negative\n",
      "Num case     2806           712\n",
      "Precision    0.97          0.91\n",
      "Recall       0.98          0.90\n",
      "F1           0.98          0.90\n"
     ]
    }
   ],
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = ada_clf_dt.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaboost on Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best parameter for learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"learning_rate\": [0.1, 1, 10]}\n",
    "\n",
    "ada_clf_lr = AdaBoostClassifier(LogisticRegression(C = 100), n_estimators=200, random_state=0)\n",
    "ada_clf_grid_lr = ms.GridSearchCV(estimator = ada_clf, param_grid = param_grid, \n",
    "                      cv = 5,\n",
    "                      return_train_score = True)\n",
    "ada_clf_grid_lr.fit(X_train, y_train)\n",
    "print(ada_clf_grid_lr.best_estimator_.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9607731665719159\n"
     ]
    }
   ],
   "source": [
    "ada_clf_lr = AdaBoostClassifier(LogisticRegression(C = 100), n_estimators=200, learning_rate=1,random_state=0)\n",
    "ada_clf_lr.fit(X_train, y_train)\n",
    "y_pred = ada_clf_lr.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.99\n",
      "Test score: 0.91\n"
     ]
    }
   ],
   "source": [
    "print('Train score: {:.2f}'.format(ada_clf_lr.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(ada_clf_lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive      2776                30\n",
      "Actual negative       108               604\n",
      "\n",
      "Accuracy        0.96\n",
      "AUC             0.99\n",
      "Macro precision 0.96\n",
      "Macro recall    0.92\n",
      " \n",
      "           Positive      Negative\n",
      "Num case     2806           712\n",
      "Precision    0.96          0.95\n",
      "Recall       0.99          0.85\n",
      "F1           0.98          0.90\n"
     ]
    }
   ],
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = ada_clf_lr.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best parameters for max_depth and learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "param_grid  = {\"max_depth\": [3,5,4,6], \"learning_rate\":[0.1,0.5,1,1.5]}\n",
    "\n",
    "gbrt = GradientBoostingClassifier(random_state=0)\n",
    "grd_clf_grid = ms.GridSearchCV(estimator = gbrt, param_grid = param_grid, \n",
    "                      cv = 5,\n",
    "                      return_train_score = True)\n",
    "grd_clf_grid.fit(X_train, y_train)\n",
    "print(grd_clf_grid.best_estimator_.learning_rate)\n",
    "print(grd_clf_grid.best_estimator_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7976122797043775\n"
     ]
    }
   ],
   "source": [
    "gbrt = GradientBoostingClassifier(max_depth=3, n_estimators=20, learning_rate=0.1, random_state=0)\n",
    "gbrt.fit(X, y)\n",
    "y_pred = gbrt.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.801\n",
      "Accuracy on test set: 0.798\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive      2806                 0\n",
      "Actual negative       712                 0\n",
      "\n",
      "Accuracy        0.80\n",
      "AUC             0.75\n",
      "Macro precision 0.40\n",
      "Macro recall    0.50\n",
      " \n",
      "           Positive      Negative\n",
      "Num case     2806           712\n",
      "Precision    0.80          0.00\n",
      "Recall       1.00          0.00\n",
      "F1           0.89          0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliri\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = gbrt.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_mod = PCA()\n",
    "pca_comps = pca_mod.fit(X_train)\n",
    "pca_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.20808102e-01 1.47728369e-01 9.24704847e-02 8.62818966e-02\n",
      " 7.95546139e-02 6.33683007e-02 5.68724855e-02 3.75353488e-02\n",
      " 1.82926473e-03 1.62454294e-03 1.46797213e-03 1.16923788e-03\n",
      " 9.21101489e-04 8.73080112e-04 8.50883039e-04 6.70549475e-04\n",
      " 6.51245218e-04 5.23935565e-04 4.79139319e-04 4.58880058e-04\n",
      " 4.41938094e-04 4.39738800e-04 4.07025992e-04 3.63265938e-04\n",
      " 3.19184667e-04 2.95739942e-04 2.71985642e-04 2.13818511e-04\n",
      " 1.85559884e-04 1.60199726e-04 1.42681289e-04 9.53887918e-05\n",
      " 6.16785530e-05 5.51660213e-05 4.94837846e-05 4.22156708e-05\n",
      " 3.78676653e-05 3.49631894e-05 3.18755740e-05 2.98158916e-05\n",
      " 2.52816664e-05 2.33289816e-05 1.97092894e-05 1.77710585e-05\n",
      " 1.49125437e-05 1.21961343e-05 9.00557788e-06 8.13821950e-06\n",
      " 6.20278673e-06 6.02904645e-06 5.58809463e-06 3.78469075e-06\n",
      " 3.48364507e-06 3.11316682e-06 3.02556057e-06 2.70778665e-06\n",
      " 2.64357785e-06 2.25212858e-06 1.87976128e-06 1.85533502e-06\n",
      " 1.69183570e-06 1.52696714e-06 1.20699709e-06 1.02074114e-06\n",
      " 9.05833214e-07 7.31575966e-07 3.24948294e-07 3.12828167e-07\n",
      " 1.90390702e-07 1.28372555e-07 1.22635788e-08 2.82034265e-09\n",
      " 2.25250541e-09 2.01891996e-09 1.59815670e-09 1.56743140e-09\n",
      " 1.22057742e-09]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(pca_comps.explained_variance_ratio_)\n",
    "print(np.sum(pca_comps.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_explained(mod):\n",
    "    comps = mod.explained_variance_ratio_\n",
    "    x = range(len(comps))\n",
    "    x = [y + 1 for y in x]          \n",
    "    plt.plot(x,comps)\n",
    "plot_explained(pca_comps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Number of features after dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10553, 10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_mod_10 = PCA(n_components = 10)\n",
    "pca_mod_10.fit(X_train)\n",
    "Comps = pca_mod_10.transform(X_train)\n",
    "Comps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=Comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_mod_10.fit(X_test)\n",
    "Comps_test = pca_mod_10.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=Comps_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running models after applying PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(20)\n",
    "knn.fit(X_train, y_train)\n",
    "y_knn_predict = knn.predict(X_test)\n",
    "y_knn_train_predict = knn.predict(X_train)\n",
    "\n",
    "report_table=0\n",
    "report_table1 = [['knn', 'k = 20', knn.score(X_train, y_train), knn.score(X_test, y_test), roc_auc_score(y_knn_train_predict, y_train), roc_auc_score(y_knn_predict, y_test) ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive      2605               201\n",
      "Actual negative       661                51\n",
      "\n",
      "Accuracy        0.75\n",
      "AUC             0.60\n",
      "Macro precision 0.50\n",
      "Macro recall    0.50\n",
      " \n",
      "           Positive      Negative\n",
      "Num case     2806           712\n",
      "Precision    0.80          0.20\n",
      "Recall       0.93          0.07\n",
      "F1           0.86          0.11\n"
     ]
    }
   ],
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = knn.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_mod = linear_model.LogisticRegression(C = 100.0) \n",
    "logistic_mod.fit(X_train, y_train)\n",
    "y_clf_predict = logistic_mod.predict(X_test)\n",
    "y_clf_train_predict = logistic_mod.predict(X_train)\n",
    "\n",
    "report_table2 = [['log reg', 'C = 100', logistic_mod.score(X_train, y_train), logistic_mod.score(X_test, y_test), roc_auc_score(y_clf_train_predict, y_train), roc_auc_score(y_clf_predict, y_test) ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive      2437               369\n",
      "Actual negative       358               354\n",
      "\n",
      "Accuracy        0.79\n",
      "AUC             0.83\n",
      "Macro precision 0.68\n",
      "Macro recall    0.68\n",
      " \n",
      "           Positive      Negative\n",
      "Num case     2806           712\n",
      "Precision    0.87          0.49\n",
      "Recall       0.87          0.50\n",
      "F1           0.87          0.49\n"
     ]
    }
   ],
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = logistic_mod.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_lin = LinearSVC(C=10)\n",
    "svc_lin.fit(X_train, y_train)\n",
    "y_svc_lin_predict_train = svc_lin.predict(X_train)\n",
    "y_svc_lin_predict = svc_lin.predict(X_test)\n",
    "\n",
    "report_table3 =[['LinearSVC', 'C = 10', svc_lin.score(X_train, y_train), svc_lin.score(X_test, y_test), roc_auc_score(y_svc_lin_predict_train, y_train), roc_auc_score(y_svc_lin_predict, y_test)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelized_svc = SVC(kernel='rbf', gamma=0.01, C=1000)\n",
    "kernelized_svc.fit(X_train, y_train)\n",
    "y_svc_ker_predict_train = kernelized_svc.predict(X_train)\n",
    "y_svc_ker_predict = kernelized_svc.predict(X_test)\n",
    "\n",
    "report_table4 = [['KernelSVC', 'C = 1000,gamma = 0.01', kernelized_svc.score(X_train, y_train), kernelized_svc.score(X_test, y_test), roc_auc_score(y_svc_ker_predict_train, y_train), roc_auc_score(y_svc_ker_predict, y_test)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth=2)\n",
    "dtree.fit(X_train, y_train)\n",
    "y_svc_tree_predict_train = dtree.predict(X_train)\n",
    "y_svc_tree_predict = dtree.predict(X_test)\n",
    "\n",
    "report_table5 =   [['DecisionTree', 'max_depth = 2', dtree.score(X_train, y_train), dtree.score(X_test, y_test), roc_auc_score(y_svc_tree_predict_train, y_train), roc_auc_score(y_svc_tree_predict, y_test)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive      1332              1474\n",
      "Actual negative        57               655\n",
      "\n",
      "Accuracy        0.56\n",
      "AUC             0.72\n",
      "Macro precision 0.63\n",
      "Macro recall    0.70\n",
      " \n",
      "           Positive      Negative\n",
      "Num case     2806           712\n",
      "Precision    0.96          0.31\n",
      "Recall       0.47          0.92\n",
      "F1           0.64          0.46\n"
     ]
    }
   ],
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = dtree.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of models after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table of Scores after applying PCA\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>Model parameter</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Train auc score</th>\n",
       "      <th>Test auc score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>k = 20</td>\n",
       "      <td>0.963044</td>\n",
       "      <td>0.754974</td>\n",
       "      <td>0.948207</td>\n",
       "      <td>0.499996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log reg</td>\n",
       "      <td>C = 100</td>\n",
       "      <td>0.960769</td>\n",
       "      <td>0.793348</td>\n",
       "      <td>0.946862</td>\n",
       "      <td>0.680770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C = 10</td>\n",
       "      <td>0.960580</td>\n",
       "      <td>0.753837</td>\n",
       "      <td>0.947512</td>\n",
       "      <td>0.622559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KernelSVC</td>\n",
       "      <td>C = 1000,gamma = 0.01</td>\n",
       "      <td>0.961433</td>\n",
       "      <td>0.766629</td>\n",
       "      <td>0.945222</td>\n",
       "      <td>0.653619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>max_depth = 2</td>\n",
       "      <td>0.936227</td>\n",
       "      <td>0.564810</td>\n",
       "      <td>0.899995</td>\n",
       "      <td>0.633310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model name        Model parameter  Train accuracy  Test accuracy  \\\n",
       "0           knn                 k = 20        0.963044       0.754974   \n",
       "1       log reg                C = 100        0.960769       0.793348   \n",
       "2     LinearSVC                 C = 10        0.960580       0.753837   \n",
       "3     KernelSVC  C = 1000,gamma = 0.01        0.961433       0.766629   \n",
       "4  DecisionTree          max_depth = 2        0.936227       0.564810   \n",
       "\n",
       "   Train auc score  Test auc score  \n",
       "0         0.948207        0.499996  \n",
       "1         0.946862        0.680770  \n",
       "2         0.947512        0.622559  \n",
       "3         0.945222        0.653619  \n",
       "4         0.899995        0.633310  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Table of Scores after applying PCA\\n\")\n",
    "report_table_all = report_table1+report_table2+report_table3+report_table4+report_table5\n",
    "report = pd.DataFrame(report_table_all,columns = ['Model name', 'Model parameter', 'Train accuracy', 'Test accuracy', 'Train auc score', 'Test auc score'])\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Table of Scores before applying PCA\n",
    "  \n",
    "#  Model name       Model param    Train acc    Test acc    Train auc     Test auc   \n",
    "#     knn              k=20          0.9909      0.9537       0.9453       0.9026\n",
    "#   log reg            C=100         0.9934      0.9767       0.9506       0.9086\n",
    "#  LinearSVC           C=10          0.9934      0.9755       0.9662       0.9148\n",
    "#  KernelSVC    C=1000,gamma=0.01    0.9684      0.9394       0.9551       0.9126\n",
    "#  DecisinTree      max_depth=2      0.9602      0.9394       0.9306       0.9002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For almost all the models, train and test score decreased after applying PCA on the data set. For Decision tree the decrease in test auc score is dramatic. It seems that we don't get better results after applying PCA but the runnning time decreased due to having less number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_org,X_test_org,y_train,y_test=train_test_split(X,y,random_state=18)\n",
    "X_train=scaler.fit_transform(X_train_org)\n",
    "X_test=scaler.transform(X_test_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=77, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = create_model, verbose = 0)\n",
    "\n",
    "param_grid = {'batch_size':[20,30,40] , 'epochs':[10, 50, 100]}\n",
    "grid_search = GridSearchCV(estimator= model, param_grid = param_grid, cv = 3)\n",
    "grid_search_result = grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 40, 'epochs': 100}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=77, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "159/159 [==============================] - 14s 91ms/step - loss: 0.6664 - acc: 0.7484\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 0s 395us/step - loss: 0.6329 - acc: 0.7799\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 0s 386us/step - loss: 0.6086 - acc: 0.7799\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 0s 397us/step - loss: 0.5846 - acc: 0.7799\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 0s 303us/step - loss: 0.5623 - acc: 0.7799\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 0s 467us/step - loss: 0.5396 - acc: 0.7799\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 0s 474us/step - loss: 0.5174 - acc: 0.7799\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 0s 514us/step - loss: 0.4954 - acc: 0.7799\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 0s 394us/step - loss: 0.4747 - acc: 0.7799\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 0s 350us/step - loss: 0.4556 - acc: 0.7799\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 0s 234us/step - loss: 0.4385 - acc: 0.7799\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 0s 266us/step - loss: 0.4237 - acc: 0.7799\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 0s 316us/step - loss: 0.4114 - acc: 0.7799\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 0s 277us/step - loss: 0.4010 - acc: 0.7799\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 0s 298us/step - loss: 0.3911 - acc: 0.7799\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 0s 277us/step - loss: 0.3823 - acc: 0.7799\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 0s 292us/step - loss: 0.3739 - acc: 0.7799\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 0s 332us/step - loss: 0.3660 - acc: 0.7799\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 0s 356us/step - loss: 0.3586 - acc: 0.7799\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 0s 273us/step - loss: 0.3519 - acc: 0.7799\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 0s 334us/step - loss: 0.3444 - acc: 0.7799\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 0s 255us/step - loss: 0.3374 - acc: 0.7799\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 0s 344us/step - loss: 0.3299 - acc: 0.7799\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 0s 291us/step - loss: 0.3222 - acc: 0.7799\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 0s 265us/step - loss: 0.3154 - acc: 0.7799\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 0s 335us/step - loss: 0.3084 - acc: 0.7799\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 0s 227us/step - loss: 0.3029 - acc: 0.7799\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - ETA: 0s - loss: 0.3694 - acc: 0.675 - 0s 278us/step - loss: 0.2976 - acc: 0.7799\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 0s 292us/step - loss: 0.2923 - acc: 0.7799\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 0s 275us/step - loss: 0.2869 - acc: 0.7799\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 0s 307us/step - loss: 0.2833 - acc: 0.7799\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 0s 254us/step - loss: 0.2786 - acc: 0.7799\n",
      "Epoch 33/100\n",
      "159/159 [==============================] - 0s 351us/step - loss: 0.2751 - acc: 0.7799\n",
      "Epoch 34/100\n",
      "159/159 [==============================] - 0s 286us/step - loss: 0.2714 - acc: 0.7799\n",
      "Epoch 35/100\n",
      "159/159 [==============================] - 0s 285us/step - loss: 0.2683 - acc: 0.7799\n",
      "Epoch 36/100\n",
      "159/159 [==============================] - 0s 252us/step - loss: 0.2653 - acc: 0.7799\n",
      "Epoch 37/100\n",
      "159/159 [==============================] - 0s 311us/step - loss: 0.2623 - acc: 0.7799\n",
      "Epoch 38/100\n",
      "159/159 [==============================] - 0s 253us/step - loss: 0.2591 - acc: 0.7799\n",
      "Epoch 39/100\n",
      "159/159 [==============================] - 0s 375us/step - loss: 0.2566 - acc: 0.7799\n",
      "Epoch 40/100\n",
      "159/159 [==============================] - 0s 247us/step - loss: 0.2538 - acc: 0.7799\n",
      "Epoch 41/100\n",
      "159/159 [==============================] - 0s 279us/step - loss: 0.2515 - acc: 0.8176\n",
      "Epoch 42/100\n",
      "159/159 [==============================] - 0s 240us/step - loss: 0.2483 - acc: 0.8931\n",
      "Epoch 43/100\n",
      "159/159 [==============================] - 0s 260us/step - loss: 0.2455 - acc: 0.8931\n",
      "Epoch 44/100\n",
      "159/159 [==============================] - 0s 357us/step - loss: 0.2430 - acc: 0.8931\n",
      "Epoch 45/100\n",
      "159/159 [==============================] - 0s 281us/step - loss: 0.2408 - acc: 0.9057\n",
      "Epoch 46/100\n",
      "159/159 [==============================] - 0s 277us/step - loss: 0.2402 - acc: 0.9057\n",
      "Epoch 47/100\n",
      "159/159 [==============================] - 0s 315us/step - loss: 0.2374 - acc: 0.9119\n",
      "Epoch 48/100\n",
      "159/159 [==============================] - 0s 258us/step - loss: 0.2364 - acc: 0.9119\n",
      "Epoch 49/100\n",
      "159/159 [==============================] - ETA: 0s - loss: 0.1976 - acc: 0.950 - 0s 338us/step - loss: 0.2350 - acc: 0.9182\n",
      "Epoch 50/100\n",
      "159/159 [==============================] - 0s 277us/step - loss: 0.2334 - acc: 0.9182\n",
      "Epoch 51/100\n",
      "159/159 [==============================] - 0s 321us/step - loss: 0.2323 - acc: 0.9245\n",
      "Epoch 52/100\n",
      "159/159 [==============================] - 0s 269us/step - loss: 0.2317 - acc: 0.9245\n",
      "Epoch 53/100\n",
      "159/159 [==============================] - 0s 418us/step - loss: 0.2305 - acc: 0.9245\n",
      "Epoch 54/100\n",
      "159/159 [==============================] - 0s 414us/step - loss: 0.2298 - acc: 0.9245\n",
      "Epoch 55/100\n",
      "159/159 [==============================] - 0s 339us/step - loss: 0.2288 - acc: 0.9245\n",
      "Epoch 56/100\n",
      "159/159 [==============================] - 0s 380us/step - loss: 0.2286 - acc: 0.9308\n",
      "Epoch 57/100\n",
      "159/159 [==============================] - 0s 402us/step - loss: 0.2275 - acc: 0.9434\n",
      "Epoch 58/100\n",
      "159/159 [==============================] - 0s 374us/step - loss: 0.2270 - acc: 0.9560\n",
      "Epoch 59/100\n",
      "159/159 [==============================] - 0s 358us/step - loss: 0.2265 - acc: 0.9560\n",
      "Epoch 60/100\n",
      "159/159 [==============================] - 0s 315us/step - loss: 0.2260 - acc: 0.9560\n",
      "Epoch 61/100\n",
      "159/159 [==============================] - 0s 305us/step - loss: 0.2247 - acc: 0.9560\n",
      "Epoch 62/100\n",
      "159/159 [==============================] - 0s 306us/step - loss: 0.2242 - acc: 0.9560\n",
      "Epoch 63/100\n",
      "159/159 [==============================] - 0s 553us/step - loss: 0.2239 - acc: 0.9560\n",
      "Epoch 64/100\n",
      "159/159 [==============================] - 0s 359us/step - loss: 0.2232 - acc: 0.9623\n",
      "Epoch 65/100\n",
      "159/159 [==============================] - 0s 337us/step - loss: 0.2226 - acc: 0.9623\n",
      "Epoch 66/100\n",
      "159/159 [==============================] - 0s 376us/step - loss: 0.2228 - acc: 0.9623\n",
      "Epoch 67/100\n",
      "159/159 [==============================] - 0s 352us/step - loss: 0.2215 - acc: 0.9623\n",
      "Epoch 68/100\n",
      "159/159 [==============================] - 0s 358us/step - loss: 0.2209 - acc: 0.9623\n",
      "Epoch 69/100\n",
      "159/159 [==============================] - 0s 530us/step - loss: 0.2205 - acc: 0.9623\n",
      "Epoch 70/100\n",
      "159/159 [==============================] - 0s 518us/step - loss: 0.2198 - acc: 0.9623\n",
      "Epoch 71/100\n",
      "159/159 [==============================] - 0s 408us/step - loss: 0.2189 - acc: 0.9623\n",
      "Epoch 72/100\n",
      "159/159 [==============================] - 0s 307us/step - loss: 0.2186 - acc: 0.9623\n",
      "Epoch 73/100\n",
      "159/159 [==============================] - 0s 296us/step - loss: 0.2183 - acc: 0.9623\n",
      "Epoch 74/100\n",
      "159/159 [==============================] - 0s 336us/step - loss: 0.2179 - acc: 0.9623\n",
      "Epoch 75/100\n",
      "159/159 [==============================] - 0s 306us/step - loss: 0.2175 - acc: 0.9623\n",
      "Epoch 76/100\n",
      "159/159 [==============================] - 0s 310us/step - loss: 0.2164 - acc: 0.9623\n",
      "Epoch 77/100\n",
      "159/159 [==============================] - 0s 290us/step - loss: 0.2158 - acc: 0.9623\n",
      "Epoch 78/100\n",
      "159/159 [==============================] - 0s 278us/step - loss: 0.2154 - acc: 0.9623\n",
      "Epoch 79/100\n",
      "159/159 [==============================] - 0s 496us/step - loss: 0.2151 - acc: 0.9623\n",
      "Epoch 80/100\n",
      "159/159 [==============================] - 0s 388us/step - loss: 0.2151 - acc: 0.9623\n",
      "Epoch 81/100\n",
      "159/159 [==============================] - 0s 384us/step - loss: 0.2145 - acc: 0.9623\n",
      "Epoch 82/100\n",
      "159/159 [==============================] - 0s 370us/step - loss: 0.2138 - acc: 0.9623\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 0s 375us/step - loss: 0.2139 - acc: 0.9623\n",
      "Epoch 84/100\n",
      "159/159 [==============================] - 0s 382us/step - loss: 0.2128 - acc: 0.9623\n",
      "Epoch 85/100\n",
      "159/159 [==============================] - 0s 431us/step - loss: 0.2126 - acc: 0.9623\n",
      "Epoch 86/100\n",
      "159/159 [==============================] - 0s 447us/step - loss: 0.2122 - acc: 0.9623\n",
      "Epoch 87/100\n",
      "159/159 [==============================] - 0s 326us/step - loss: 0.2118 - acc: 0.9623\n",
      "Epoch 88/100\n",
      "159/159 [==============================] - 0s 329us/step - loss: 0.2114 - acc: 0.9623\n",
      "Epoch 89/100\n",
      "159/159 [==============================] - 0s 344us/step - loss: 0.2108 - acc: 0.9623\n",
      "Epoch 90/100\n",
      "159/159 [==============================] - 0s 385us/step - loss: 0.2106 - acc: 0.9623\n",
      "Epoch 91/100\n",
      "159/159 [==============================] - 0s 420us/step - loss: 0.2104 - acc: 0.9623\n",
      "Epoch 92/100\n",
      "159/159 [==============================] - 0s 346us/step - loss: 0.2100 - acc: 0.9623\n",
      "Epoch 93/100\n",
      "159/159 [==============================] - 0s 400us/step - loss: 0.2096 - acc: 0.9623\n",
      "Epoch 94/100\n",
      "159/159 [==============================] - 0s 389us/step - loss: 0.2092 - acc: 0.9623\n",
      "Epoch 95/100\n",
      "159/159 [==============================] - 0s 321us/step - loss: 0.2089 - acc: 0.9623\n",
      "Epoch 96/100\n",
      "159/159 [==============================] - 0s 375us/step - loss: 0.2082 - acc: 0.9623\n",
      "Epoch 97/100\n",
      "159/159 [==============================] - 0s 334us/step - loss: 0.2080 - acc: 0.9623\n",
      "Epoch 98/100\n",
      "159/159 [==============================] - 0s 495us/step - loss: 0.2075 - acc: 0.9623\n",
      "Epoch 99/100\n",
      "159/159 [==============================] - 0s 461us/step - loss: 0.2071 - acc: 0.9623\n",
      "Epoch 100/100\n",
      "159/159 [==============================] - 0s 441us/step - loss: 0.2070 - acc: 0.9623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1783105e160>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 7s 124ms/step\n",
      "\n",
      "acc: 94.34%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
